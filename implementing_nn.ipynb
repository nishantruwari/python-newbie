{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishantruwari/python-newbie/blob/main/implementing_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZrLZ2bcaBZa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "par38jCgkrqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/train.csv.zip')"
      ],
      "metadata": {
        "id": "aihqmBaaaNsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data)"
      ],
      "metadata": {
        "id": "usgfUUIMcjiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m, n = data.shape\n",
        "np.random.shuffle(data)  # Shuffle before splitting into dev and training sets\n",
        "\n",
        "# Split the data\n",
        "data_dev = data[0:1000].T\n",
        "Y_dev = data_dev[0]\n",
        "X_dev = data_dev[1:n]\n",
        "X_dev = X_dev / 255.\n",
        "\n",
        "data_train = data[1000:m].T\n",
        "Y_train = data_train[0]\n",
        "X_train = data_train[1:n]\n",
        "X_train = X_train / 255.\n",
        "\n",
        "# Shape of X_train (m_train examples)\n",
        "_, m_train = X_train.shape"
      ],
      "metadata": {
        "id": "pFMk5DrLcne6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_params():\n",
        "    W1 = np.random.randn(128, 784) * 0.01  # 128 neurons in the first hidden layer\n",
        "    b1 = np.zeros((128, 1))\n",
        "    W2 = np.random.randn(64, 128) * 0.01  # 64 neurons in the second hidden layer\n",
        "    b2 = np.zeros((64, 1))\n",
        "    W3 = np.random.randn(10, 64) * 0.01   # 10 outputs (one for each digit)\n",
        "    b3 = np.zeros((10, 1))\n",
        "    return W1, b1, W2, b2, W3, b3\n"
      ],
      "metadata": {
        "id": "BBx9guF7crf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def leaky_relu(x, epsilon=1-8):\n",
        "# Step 1: Normalize x using Gaussian scaling\n",
        "  scaled_x = x / np.sqrt(x**2 + epsilon)\n",
        "# Step 2: Apply GLT-inspired transformation\n",
        "  result = np.where(\n",
        "      scaled_x > 0,\n",
        "      scaled_x* x=,\n",
        "       scaled_x\n",
        "# Non-linear operation for positive inputs\n",
        "# Normalized behavior for negative inputs\n",
        "return\n",
        "result\n",
        "def leaky_relu_deriv(x, epsilon=1e-8):\n",
        "    # Step 1: Normalize x using Gaussian scaling\n",
        "    scaled_x = x / np.sqrt(x**2 + epsilon)\n",
        "\n",
        "    # Step 2: Compute the derivative piecewise\n",
        "    derivative = np.where(\n",
        "        scaled_x > 0,\n",
        "        1,  # Derivative of (scaled_x - floor(scaled_x)) is 1 for positive inputs\n",
        "        (1 - np.abs(scaled_x)) / ((np.abs(scaled_x) + 1)**2)  # Derivative for negative inputs\n",
        "    )\n",
        "    return derivative\n"
      ],
      "metadata": {
        "id": "9Nlf8o6Bcxps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(Z):\n",
        "    exp_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True))  # Avoid overflow\n",
        "    return exp_Z / np.sum(exp_Z, axis=0, keepdims=True)"
      ],
      "metadata": {
        "id": "1Tq5bJvKdNw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_prop(W1, b1, W2, b2, W3, b3, X):\n",
        "    Z1 = W1.dot(X) + b1\n",
        "    A1 = leaky_relu(Z1)  # Using Leaky ReLU here\n",
        "    Z2 = W2.dot(A1) + b2\n",
        "    A2 = leaky_relu(Z2)  # Second hidden layer with Leaky ReLU\n",
        "    Z3 = W3.dot(A2) + b3\n",
        "    A3 = softmax(Z3)     # Output layer\n",
        "    return Z1, A1, Z2, A2, Z3, A3"
      ],
      "metadata": {
        "id": "EE1pSAQ8dlW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(Y):\n",
        "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
        "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
        "    return one_hot_Y.T"
      ],
      "metadata": {
        "id": "Q4hcAq1Gd59b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_prop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X, Y, m_train):\n",
        "    one_hot_Y = one_hot(Y)\n",
        "\n",
        "    # Compute derivatives for output layer\n",
        "    dZ3 = A3 - one_hot_Y\n",
        "    dW3 = (1 / m_train) * dZ3.dot(A2.T)\n",
        "    db3 = (1 / m_train) * np.sum(dZ3, axis=1, keepdims=True)\n",
        "\n",
        "    # Compute derivatives for second hidden layer\n",
        "    dZ2 = W3.T.dot(dZ3) * leaky_relu_deriv(Z2)\n",
        "    dW2 = (1 / m_train) * dZ2.dot(A1.T)\n",
        "    db2 = (1 / m_train) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "\n",
        "    # Compute derivatives for first hidden layer\n",
        "    dZ1 = W2.T.dot(dZ2) * leaky_relu_deriv(Z1)\n",
        "    dW1 = (1 / m_train) * dZ1.dot(X.T)\n",
        "    db1 = (1 / m_train) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "\n",
        "    return dW1, db1, dW2, db2, dW3, db3\n"
      ],
      "metadata": {
        "id": "_HpcgxHVd87h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_params_with_adam(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3,\n",
        "                            mW1, mb1, mW2, mb2, mW3, mb3, vW1, vb1, vW2, vb2, vW3, vb3,\n",
        "                            alpha, beta1, beta2, epsilon, t):\n",
        "    # Update moving averages of gradients (first moment)\n",
        "    mW1 = beta1 * mW1 + (1 - beta1) * dW1\n",
        "    mb1 = beta1 * mb1 + (1 - beta1) * db1\n",
        "    mW2 = beta1 * mW2 + (1 - beta1) * dW2\n",
        "    mb2 = beta1 * mb2 + (1 - beta1) * db2\n",
        "    mW3 = beta1 * mW3 + (1 - beta1) * dW3\n",
        "    mb3 = beta1 * mb3 + (1 - beta1) * db3\n",
        "\n",
        "    # Update moving averages of squared gradients (second moment)\n",
        "    vW1 = beta2 * vW1 + (1 - beta2) * (dW1**2)\n",
        "    vb1 = beta2 * vb1 + (1 - beta2) * (db1**2)\n",
        "    vW2 = beta2 * vW2 + (1 - beta2) * (dW2**2)\n",
        "    vb2 = beta2 * vb2 + (1 - beta2) * (db2**2)\n",
        "    vW3 = beta2 * vW3 + (1 - beta2) * (dW3**2)\n",
        "    vb3 = beta2 * vb3 + (1 - beta2) * (db3**2)\n",
        "\n",
        "    # Correct bias in moving averages\n",
        "    mW1_corrected = mW1 / (1 - beta1**t)\n",
        "    mb1_corrected = mb1 / (1 - beta1**t)\n",
        "    mW2_corrected = mW2 / (1 - beta1**t)\n",
        "    mb2_corrected = mb2 / (1 - beta1**t)\n",
        "    mW3_corrected = mW3 / (1 - beta1**t)\n",
        "    mb3_corrected = mb3 / (1 - beta1**t)\n",
        "\n",
        "    vW1_corrected = vW1 / (1 - beta2**t)\n",
        "    vb1_corrected = vb1 / (1 - beta2**t)\n",
        "    vW2_corrected = vW2 / (1 - beta2**t)\n",
        "    vb2_corrected = vb2 / (1 - beta2**t)\n",
        "    vW3_corrected = vW3 / (1 - beta2**t)\n",
        "    vb3_corrected = vb3 / (1 - beta2**t)\n",
        "\n",
        "    # Update parameters\n",
        "    W1 -= alpha * mW1_corrected / (np.sqrt(vW1_corrected) + epsilon)\n",
        "    b1 -= alpha * mb1_corrected / (np.sqrt(vb1_corrected) + epsilon)\n",
        "    W2 -= alpha * mW2_corrected / (np.sqrt(vW2_corrected) + epsilon)\n",
        "    b2 -= alpha * mb2_corrected / (np.sqrt(vb2_corrected) + epsilon)\n",
        "    W3 -= alpha * mW3_corrected / (np.sqrt(vW3_corrected) + epsilon)\n",
        "    b3 -= alpha * mb3_corrected / (np.sqrt(vb3_corrected) + epsilon)\n",
        "\n",
        "    return W1, b1, W2, b2, W3, b3, mW1, mb1, mW2, mb2, mW3, mb3, vW1, vb1, vW2, vb2, vW3, vb3\n",
        "\n"
      ],
      "metadata": {
        "id": "kLDKLvRXejZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, alpha, iterations, beta1, beta2, epsilon):\n",
        "    # Initialize parameters\n",
        "    W1, b1, W2, b2, W3, b3 = init_params()\n",
        "    mW1, mb1, mW2, mb2, mW3, mb3 = np.zeros_like(W1), np.zeros_like(b1), np.zeros_like(W2), np.zeros_like(b2), np.zeros_like(W3), np.zeros_like(b3)\n",
        "    vW1, vb1, vW2, vb2, vW3, vb3 = np.zeros_like(W1), np.zeros_like(b1), np.zeros_like(W2), np.zeros_like(b2), np.zeros_like(W3), np.zeros_like(b3)\n",
        "\n",
        "    for t in range(1, iterations + 1):\n",
        "        # Forward propagation\n",
        "        Z1, A1, Z2, A2, Z3, A3 = forward_prop(W1, b1, W2, b2, W3, b3, X)\n",
        "\n",
        "        # Backward propagation\n",
        "        dW1, db1, dW2, db2, dW3, db3 = backward_prop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X, Y, X.shape[1])\n",
        "\n",
        "        # Update parameters using Adam\n",
        "        W1, b1, W2, b2, W3, b3, mW1, mb1, mW2, mb2, mW3, mb3, vW1, vb1, vW2, vb2, vW3, vb3 = update_params_with_adam(\n",
        "            W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3,\n",
        "            mW1, mb1, mW2, mb2, mW3, mb3, vW1, vb1, vW2, vb2, vW3, vb3,\n",
        "            alpha, beta1, beta2, epsilon, t\n",
        "        )\n",
        "\n",
        "        # Print progress\n",
        "        if t % 10 == 0:\n",
        "            predictions = make_predictions(X, W1, b1, W2, b2, W3, b3)\n",
        "            accuracy = get_accuracy(predictions, Y)\n",
        "            print(f\"Iteration {t}: Accuracy = {accuracy:.4f}\")\n",
        "\n",
        "    return W1, b1, W2, b2, W3, b3\n"
      ],
      "metadata": {
        "id": "Wd31wNJgen58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(X, W1, b1, W2, b2, W3, b3):\n",
        "    _, _, _, _, _, A3 = forward_prop(W1, b1, W2, b2, W3, b3, X)\n",
        "    predictions = get_predictions(A3)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "3KyuNxnXeuoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(A):\n",
        "    return np.argmax(A, axis=0)\n"
      ],
      "metadata": {
        "id": "K24GrblTeyJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(predictions, Y):\n",
        "    return np.sum(predictions == Y) / Y.size\n"
      ],
      "metadata": {
        "id": "E8HlD-lLe0eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize parameters and train\n",
        "alpha = 0.001\n",
        "iterations = 200\n",
        "beta1 = 0.9\n",
        "beta2 = 0.999\n",
        "epsilon = 1e-8\n",
        "\n",
        "W1, b1, W2, b2, W3, b3 = gradient_descent(X_train, Y_train, alpha, iterations, beta1, beta2, epsilon)\n",
        "\n",
        "# Evaluate on dev set\n",
        "dev_predictions = make_predictions(X_dev, W1, b1, W2, b2, W3, b3)\n",
        "accuracy = get_accuracy(dev_predictions, Y_dev)\n",
        "print(f\"Dev Set Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br-b5Vd7e3UV",
        "outputId": "5d53c144-0ce8-424b-cd08-e95d94cf48bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 10: Accuracy = 0.4505\n",
            "Iteration 20: Accuracy = 0.4467\n",
            "Iteration 30: Accuracy = 0.6017\n",
            "Iteration 40: Accuracy = 0.7050\n",
            "Iteration 50: Accuracy = 0.7749\n",
            "Iteration 60: Accuracy = 0.8234\n",
            "Iteration 70: Accuracy = 0.8559\n",
            "Iteration 80: Accuracy = 0.8770\n",
            "Iteration 90: Accuracy = 0.8905\n",
            "Iteration 100: Accuracy = 0.9009\n",
            "Iteration 110: Accuracy = 0.9076\n",
            "Iteration 120: Accuracy = 0.9146\n",
            "Iteration 130: Accuracy = 0.9199\n",
            "Iteration 140: Accuracy = 0.9247\n",
            "Iteration 150: Accuracy = 0.9299\n",
            "Iteration 160: Accuracy = 0.9337\n",
            "Iteration 170: Accuracy = 0.9386\n",
            "Iteration 180: Accuracy = 0.9421\n",
            "Iteration 190: Accuracy = 0.9457\n",
            "Iteration 200: Accuracy = 0.9495\n",
            "Dev Set Accuracy: 0.929\n"
          ]
        }
      ]
    }
  ]
}